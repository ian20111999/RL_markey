"""scan_env_baseline.py: æƒæç’°å¢ƒåƒæ•¸ä¸¦ä½¿ç”¨å›ºå®š Baseline ç­–ç•¥é€²è¡Œæ¸¬è©¦ï¼Œå°‹æ‰¾åˆç†åƒæ•¸çµ„åˆã€‚"""
from __future__ import annotations

import argparse
import itertools
import sys
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd

# ç¢ºä¿å¯ä»¥ import envs
ROOT = Path(__file__).resolve().parent.parent
sys.path.append(str(ROOT))

from envs.historical_market_making_env import HistoricalMarketMakingEnv
from utils.config import load_config

# å»ºè­°åƒæ•¸ç¯„åœ
# fee_rate: å›ºå®š 0.0004
# base_spread: 10.0 ~ 30.0 (å› ç‚º 0.0004 * 30000 = 12ï¼ŒSpread å¿…é ˆå¤§æ–¼ 12 æ‰èƒ½è¦†è“‹æ‰‹çºŒè²»)
# lambda_inv: 0.0002, 0.0005
# alpha: å›ºå®š 0.5

FEE_RATES = [0.0004]
BASE_SPREADS = [10.0, 15.0, 20.0, 25.0, 30.0]
LAMBDA_INVS = [0.0002, 0.0005]
ALPHA = 0.5

DEFAULT_CONFIG_PATH = ROOT / "configs" / "env_baseline.yaml"

def run_baseline_episode(env: HistoricalMarketMakingEnv) -> Dict[str, float]:
    """åŸ·è¡Œå–®å€‹ episode çš„ baseline ç­–ç•¥ (å›ºå®š spread/skew)ã€‚"""
    obs, _ = env.reset()
    done = False
    
    # Baseline ç­–ç•¥ï¼šå§‹çµ‚ä¿æŒä¸­æ€§
    # action[0] (spread) = 0.0 -> ä½¿ç”¨ base_spread * (1 + alpha * 0) = base_spread
    # action[1] (skew) = 0.0 -> skew = beta * 0 = 0
    action = np.array([0.0, 0.0], dtype=np.float32)
    
    final_info = {}
    
    while not done:
        obs, reward, terminated, truncated, info = env.step(action)
        done = terminated or truncated
        if done:
            final_info = info
            
    return {
        "gross_pnl": final_info.get("episode_gross_pnl", 0.0),
        "fees": final_info.get("episode_fees", 0.0),
        "penalty_inv": final_info.get("episode_penalty_inv", 0.0),
        "net_pnl": final_info.get("episode_net_pnl", 0.0),
    }

def main():
    parser = argparse.ArgumentParser(description="æƒæç’°å¢ƒåƒæ•¸ä¸¦æª¢æŸ¥ Baseline è¡¨ç¾")
    parser.add_argument("--episodes", type=int, default=5, help="æ¯å€‹çµ„åˆæ¸¬è©¦çš„ episode æ•¸")
    parser.add_argument("--output", type=str, default="env_baseline_scan_results.csv", help="çµæœè¼¸å‡º CSV æª”å")
    args = parser.parse_args()

    # è¼‰å…¥é è¨­ config ä»¥ç²å–è³‡æ–™è·¯å¾‘èˆ‡åˆ†å‰²è¨­å®š
    base_config = load_config(DEFAULT_CONFIG_PATH)
    
    # æº–å‚™æ¸¬è©¦è³‡æ–™æ®µ
    test_split = base_config.data_split
    date_range = (test_split.get("test_start"), test_split.get("test_end"))
    
    results = []
    
    # ç”¢ç”Ÿæ‰€æœ‰åƒæ•¸çµ„åˆ
    combinations = list(itertools.product(FEE_RATES, BASE_SPREADS, LAMBDA_INVS))
    total_combos = len(combinations)
    
    print(f"ğŸš€ é–‹å§‹æƒæ {total_combos} çµ„åƒæ•¸çµ„åˆ...")
    print(f"ğŸ“… æ¸¬è©¦è³‡æ–™æ®µ: {date_range}")
    print(f"{'Fee':<10} | {'Spread':<10} | {'L_Inv':<10} | {'Gross PnL':<12} | {'Fees':<10} | {'Net PnL':<12}")
    print("-" * 80)

    for i, (fee, spread, l_inv) in enumerate(combinations, 1):
        # å»ºç«‹ç’°å¢ƒ
        env_kwargs = {
            "csv_path": base_config.env["csv_path"],
            "episode_length": base_config.env["episode_length"],
            "fee_rate": fee,
            "base_spread": spread,
            "lambda_inv": l_inv,
            "alpha": ALPHA,
            "max_inventory": base_config.env["max_inventory"],
            "random_start": True,
            "date_range": date_range,
        }
        
        # ç‚ºäº†é¿å…æ¯æ¬¡éƒ½é‡æ–°è®€å– CSVï¼Œç†æƒ³ä¸Šæ‡‰è©²é‡ç”¨ç’°å¢ƒï¼Œä½†ç‚ºäº†ç¢ºä¿åƒæ•¸ä¹¾æ·¨ï¼Œé€™è£¡æ¯æ¬¡é‡å»º
        # è‹¥æ•ˆèƒ½å¤ªå·®å¯å„ªåŒ–
        env = HistoricalMarketMakingEnv(**env_kwargs)
        
        metrics_accum = {"gross_pnl": [], "fees": [], "penalty_inv": [], "net_pnl": []}
        
        for ep in range(args.episodes):
            # è¨­å®š seed ç¢ºä¿å¯é‡ç¾æ€§ï¼Œä½†ä¸åŒ episode è¦ä¸åŒ
            env.reset(seed=1000 + ep)
            res = run_baseline_episode(env)
            for k, v in res.items():
                metrics_accum[k].append(v)
        
        env.close()
        
        # è¨ˆç®—å¹³å‡
        avg_gross = np.mean(metrics_accum["gross_pnl"])
        avg_fees = np.mean(metrics_accum["fees"])
        avg_penalty = np.mean(metrics_accum["penalty_inv"])
        avg_net = np.mean(metrics_accum["net_pnl"])
        
        results.append({
            "fee_rate": fee,
            "base_spread": spread,
            "lambda_inv": l_inv,
            "avg_gross_pnl": avg_gross,
            "avg_fees": avg_fees,
            "avg_penalty_inv": avg_penalty,
            "avg_net_pnl": avg_net
        })
        
        print(f"{fee:<10.4f} | {spread:<10.1f} | {l_inv:<10.4f} | {avg_gross:<12.2f} | {avg_fees:<10.2f} | {avg_net:<12.2f}")

    # è½‰ç‚º DataFrame ä¸¦æ’åº
    df = pd.DataFrame(results)
    df = df.sort_values(by="avg_net_pnl", ascending=False)
    
    # å­˜æª”
    output_path = ROOT / args.output
    df.to_csv(output_path, index=False)
    print("-" * 80)
    print(f"âœ… æƒæå®Œæˆï¼çµæœå·²å„²å­˜è‡³: {output_path}")
    
    print("\nğŸ† Top 5 æœ€ä½³åƒæ•¸çµ„åˆ (ä¾ Net PnL):")
    print(df.head(5).to_string(index=False))
    
    print("\nğŸ’¡ å»ºè­°ï¼š")
    print("1. è§€å¯Ÿ avg_gross_pnl æ˜¯å¦æ¥è¿‘ 0 æˆ–ç‚ºæ­£ï¼Œè¡¨ç¤ºåšå¸‚æœ¬èº«æœ‰ç²åˆ©æ½›åŠ›ã€‚")
    print("2. è‹¥ avg_fees éé«˜å°è‡´ Net PnL å¤§å¹…ç‚ºè² ï¼Œè€ƒæ…®èª¿é«˜ base_spread æˆ–é™ä½ fee_rate (è‹¥å¯é¸)ã€‚")
    print("3. è‹¥ avg_penalty_inv éé«˜ï¼Œè¡¨ç¤ºåº«å­˜æ§åˆ¶ä¸æ˜“ï¼Œå¯èª¿æ•´ lambda_inv æˆ–æª¢æŸ¥ç­–ç•¥ã€‚")

if __name__ == "__main__":
    main()
