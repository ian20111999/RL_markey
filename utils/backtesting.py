"""
utils/backtesting.py
å®Œæ•´å›æ¸¬æ¡†æ¶

å¯¦ä½œå°ˆæ¥­ç´šå›æ¸¬åŠŸèƒ½:
- Walk-Forward Analysis: æ»¾å‹•çª—å£é©—è­‰
- Monte Carlo Simulation: è’™åœ°å¡ç¾…æ¨¡æ“¬
- Transaction Cost Analysis: äº¤æ˜“æˆæœ¬åˆ†æ
- Robustness Testing: ç©©å¥æ€§æ¸¬è©¦

ç”¨æ³•:
    from utils.backtesting import BacktestEngine, WalkForwardAnalyzer
    
    engine = BacktestEngine(env_factory)
    results = engine.run_backtest(model, start_date, end_date)
    
    analyzer = WalkForwardAnalyzer(engine)
    wf_results = analyzer.run(train_window=30, test_window=7)
"""
from __future__ import annotations

from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Callable, Dict, List, Optional, Tuple
import json

import numpy as np
import pandas as pd
from stable_baselines3.common.base_class import BaseAlgorithm


# =============================================================================
# Data Classes
# =============================================================================

@dataclass
class BacktestResult:
    """å›æ¸¬çµæœ"""
    # åŸºæœ¬è³‡è¨Š
    start_date: str
    end_date: str
    n_episodes: int
    
    # ç¸¾æ•ˆæŒ‡æ¨™
    total_pnl: float
    avg_pnl: float
    std_pnl: float
    sharpe_ratio: float
    max_drawdown: float
    calmar_ratio: float
    
    # äº¤æ˜“çµ±è¨ˆ
    total_trades: int
    win_rate: float
    avg_win: float
    avg_loss: float
    profit_factor: float
    
    # é¢¨éšªæŒ‡æ¨™
    var_95: float
    cvar_95: float
    
    # è©³ç´°æ•¸æ“š
    pnl_series: List[float] = field(default_factory=list)
    equity_curve: List[float] = field(default_factory=list)
    drawdown_series: List[float] = field(default_factory=list)
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "start_date": self.start_date,
            "end_date": self.end_date,
            "n_episodes": self.n_episodes,
            "total_pnl": self.total_pnl,
            "avg_pnl": self.avg_pnl,
            "std_pnl": self.std_pnl,
            "sharpe_ratio": self.sharpe_ratio,
            "max_drawdown": self.max_drawdown,
            "calmar_ratio": self.calmar_ratio,
            "total_trades": self.total_trades,
            "win_rate": self.win_rate,
            "profit_factor": self.profit_factor,
            "var_95": self.var_95,
            "cvar_95": self.cvar_95,
        }


@dataclass
class WalkForwardResult:
    """Walk-Forward åˆ†æçµæœ"""
    windows: List[Dict[str, Any]]
    aggregate_metrics: Dict[str, float]
    stability_score: float
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "windows": self.windows,
            "aggregate_metrics": self.aggregate_metrics,
            "stability_score": self.stability_score,
        }


# =============================================================================
# Backtest Engine
# =============================================================================

class BacktestEngine:
    """å›æ¸¬å¼•æ“"""
    
    def __init__(
        self,
        env_factory: Callable,
        initial_capital: float = 100_000,
        transaction_cost_bps: float = 4.0,  # äº¤æ˜“æˆæœ¬ (bps)
    ):
        """
        Args:
            env_factory: å»ºç«‹ç’°å¢ƒçš„å‡½æ•¸
            initial_capital: åˆå§‹è³‡é‡‘
            transaction_cost_bps: äº¤æ˜“æˆæœ¬ï¼ˆåŸºé»ï¼‰
        """
        self.env_factory = env_factory
        self.initial_capital = initial_capital
        self.transaction_cost_bps = transaction_cost_bps
    
    def run_backtest(
        self,
        model: BaseAlgorithm,
        n_episodes: int = 10,
        deterministic: bool = True,
    ) -> BacktestResult:
        """
        åŸ·è¡Œå›æ¸¬
        
        Args:
            model: RL æ¨¡å‹
            n_episodes: å›æ¸¬ episode æ•¸
            deterministic: æ˜¯å¦ä½¿ç”¨ç¢ºå®šæ€§ç­–ç•¥
        
        Returns:
            å›æ¸¬çµæœ
        """
        env = self.env_factory()
        
        all_pnls = []
        all_trades = []
        all_equity_curves = []
        
        for ep in range(n_episodes):
            obs, _ = env.reset()
            done = False
            
            episode_pnl = 0.0
            episode_trades = []
            episode_equity = [self.initial_capital]
            
            while not done:
                action, _ = model.predict(obs, deterministic=deterministic)
                obs, reward, terminated, truncated, info = env.step(action)
                done = terminated or truncated
                
                # è¨˜éŒ„äº¤æ˜“
                if info.get("trades_count", 0) > 0:
                    episode_trades.append({
                        "step": info.get("step", 0),
                        "pnl": reward,
                        "inventory": info.get("inventory", 0),
                    })
                
                episode_pnl += reward
                episode_equity.append(episode_equity[-1] + reward)
            
            all_pnls.append(episode_pnl)
            all_trades.extend(episode_trades)
            all_equity_curves.append(episode_equity)
        
        env.close()
        
        # è¨ˆç®—æŒ‡æ¨™
        return self._compute_metrics(all_pnls, all_trades, all_equity_curves, n_episodes)
    
    def _compute_metrics(
        self,
        pnls: List[float],
        trades: List[Dict],
        equity_curves: List[List[float]],
        n_episodes: int,
    ) -> BacktestResult:
        """è¨ˆç®—å›æ¸¬æŒ‡æ¨™"""
        pnls = np.array(pnls)
        
        # åŸºæœ¬çµ±è¨ˆ
        total_pnl = float(np.sum(pnls))
        avg_pnl = float(np.mean(pnls))
        std_pnl = float(np.std(pnls)) if len(pnls) > 1 else 0.0
        
        # Sharpe Ratio
        sharpe = avg_pnl / std_pnl if std_pnl > 0 else 0.0
        
        # åˆä½µ equity curve
        max_len = max(len(eq) for eq in equity_curves)
        padded_curves = []
        for eq in equity_curves:
            if len(eq) < max_len:
                eq = eq + [eq[-1]] * (max_len - len(eq))
            padded_curves.append(eq)
        
        avg_equity = np.mean(padded_curves, axis=0)
        
        # Max Drawdown
        peak = np.maximum.accumulate(avg_equity)
        drawdown = (peak - avg_equity) / peak
        max_drawdown = float(np.max(drawdown))
        
        # Calmar Ratio
        total_return = (avg_equity[-1] - avg_equity[0]) / avg_equity[0]
        calmar = total_return / max_drawdown if max_drawdown > 0 else 0.0
        
        # äº¤æ˜“çµ±è¨ˆ
        trade_pnls = [t["pnl"] for t in trades] if trades else [0]
        wins = [p for p in trade_pnls if p > 0]
        losses = [p for p in trade_pnls if p < 0]
        
        win_rate = len(wins) / len(trade_pnls) if trade_pnls else 0.0
        avg_win = float(np.mean(wins)) if wins else 0.0
        avg_loss = float(np.mean(losses)) if losses else 0.0
        
        profit_factor = abs(sum(wins) / sum(losses)) if losses and sum(losses) != 0 else float('inf')
        
        # VaR å’Œ CVaR
        var_95 = float(np.percentile(pnls, 5))
        cvar_95 = float(np.mean(pnls[pnls <= var_95])) if len(pnls[pnls <= var_95]) > 0 else var_95
        
        return BacktestResult(
            start_date="",
            end_date="",
            n_episodes=n_episodes,
            total_pnl=total_pnl,
            avg_pnl=avg_pnl,
            std_pnl=std_pnl,
            sharpe_ratio=sharpe,
            max_drawdown=max_drawdown,
            calmar_ratio=calmar,
            total_trades=len(trades),
            win_rate=win_rate,
            avg_win=avg_win,
            avg_loss=avg_loss,
            profit_factor=profit_factor,
            var_95=var_95,
            cvar_95=cvar_95,
            pnl_series=pnls.tolist(),
            equity_curve=avg_equity.tolist(),
            drawdown_series=drawdown.tolist(),
        )


# =============================================================================
# Walk-Forward Analyzer
# =============================================================================

class WalkForwardAnalyzer:
    """
    Walk-Forward åˆ†æå™¨
    
    æ»¾å‹•çª—å£é©—è­‰ç­–ç•¥çš„ç©©å®šæ€§
    """
    
    def __init__(
        self,
        data: pd.DataFrame,
        env_factory_with_data: Callable[[pd.DataFrame], Any],
        model_factory: Callable[[Any], BaseAlgorithm],
        train_timesteps: int = 50_000,
    ):
        """
        Args:
            data: å®Œæ•´æ•¸æ“š
            env_factory_with_data: ä½¿ç”¨æŒ‡å®šæ•¸æ“šå»ºç«‹ç’°å¢ƒçš„å‡½æ•¸
            model_factory: å»ºç«‹æ¨¡å‹çš„å‡½æ•¸
            train_timesteps: æ¯å€‹çª—å£çš„è¨“ç·´æ­¥æ•¸
        """
        self.data = data
        self.env_factory_with_data = env_factory_with_data
        self.model_factory = model_factory
        self.train_timesteps = train_timesteps
    
    def run(
        self,
        train_window_days: int = 30,
        test_window_days: int = 7,
        step_days: int = 7,
        verbose: bool = True,
    ) -> WalkForwardResult:
        """
        åŸ·è¡Œ Walk-Forward åˆ†æ
        
        Args:
            train_window_days: è¨“ç·´çª—å£ï¼ˆå¤©ï¼‰
            test_window_days: æ¸¬è©¦çª—å£ï¼ˆå¤©ï¼‰
            step_days: æ­¥é€²ï¼ˆå¤©ï¼‰
            verbose: æ˜¯å¦è¼¸å‡ºé€²åº¦
        
        Returns:
            åˆ†æçµæœ
        """
        # å‡è¨­æ•¸æ“šæ˜¯åˆ†é˜ç´šï¼Œè¨ˆç®—ç´¢å¼•
        minutes_per_day = 24 * 60
        train_window = train_window_days * minutes_per_day
        test_window = test_window_days * minutes_per_day
        step = step_days * minutes_per_day
        
        windows = []
        total_len = len(self.data)
        
        start_idx = 0
        window_num = 0
        
        while start_idx + train_window + test_window <= total_len:
            window_num += 1
            
            # åˆ‡å‰²æ•¸æ“š
            train_end = start_idx + train_window
            test_end = train_end + test_window
            
            train_data = self.data.iloc[start_idx:train_end].reset_index(drop=True)
            test_data = self.data.iloc[train_end:test_end].reset_index(drop=True)
            
            if verbose:
                print(f"\n[Window {window_num}] "
                      f"Train: {start_idx}-{train_end}, "
                      f"Test: {train_end}-{test_end}")
            
            # è¨“ç·´
            train_env = self.env_factory_with_data(train_data)
            model = self.model_factory(train_env)
            model.learn(total_timesteps=self.train_timesteps, progress_bar=verbose)
            train_env.close()
            
            # æ¸¬è©¦
            test_env = self.env_factory_with_data(test_data)
            test_result = self._evaluate_window(model, test_env)
            test_env.close()
            
            windows.append({
                "window": window_num,
                "train_start": start_idx,
                "train_end": train_end,
                "test_start": train_end,
                "test_end": test_end,
                "metrics": test_result,
            })
            
            if verbose:
                print(f"  Test PnL: {test_result['avg_pnl']:.2f}, "
                      f"Sharpe: {test_result['sharpe']:.4f}")
            
            start_idx += step
        
        # è¨ˆç®—å½™ç¸½æŒ‡æ¨™
        aggregate = self._compute_aggregate_metrics(windows)
        stability = self._compute_stability_score(windows)
        
        return WalkForwardResult(
            windows=windows,
            aggregate_metrics=aggregate,
            stability_score=stability,
        )
    
    def _evaluate_window(self, model: BaseAlgorithm, env, n_episodes: int = 5) -> Dict[str, float]:
        """è©•ä¼°å–®ä¸€çª—å£"""
        pnls = []
        
        for _ in range(n_episodes):
            obs, _ = env.reset()
            done = False
            episode_pnl = 0.0
            
            while not done:
                action, _ = model.predict(obs, deterministic=True)
                obs, reward, terminated, truncated, _ = env.step(action)
                done = terminated or truncated
                episode_pnl += reward
            
            pnls.append(episode_pnl)
        
        pnls = np.array(pnls)
        avg_pnl = float(np.mean(pnls))
        std_pnl = float(np.std(pnls)) if len(pnls) > 1 else 0.01
        
        return {
            "avg_pnl": avg_pnl,
            "std_pnl": std_pnl,
            "sharpe": avg_pnl / std_pnl if std_pnl > 0 else 0.0,
            "max_pnl": float(np.max(pnls)),
            "min_pnl": float(np.min(pnls)),
        }
    
    def _compute_aggregate_metrics(self, windows: List[Dict]) -> Dict[str, float]:
        """è¨ˆç®—å½™ç¸½æŒ‡æ¨™"""
        avg_pnls = [w["metrics"]["avg_pnl"] for w in windows]
        sharpes = [w["metrics"]["sharpe"] for w in windows]
        
        return {
            "overall_avg_pnl": float(np.mean(avg_pnls)),
            "overall_std_pnl": float(np.std(avg_pnls)),
            "overall_sharpe": float(np.mean(sharpes)),
            "sharpe_std": float(np.std(sharpes)),
            "positive_windows": sum(1 for p in avg_pnls if p > 0) / len(avg_pnls),
            "n_windows": len(windows),
        }
    
    def _compute_stability_score(self, windows: List[Dict]) -> float:
        """
        è¨ˆç®—ç©©å®šæ€§åˆ†æ•¸
        
        åŸºæ–¼ç¸¾æ•ˆçš„ä¸€è‡´æ€§
        """
        if len(windows) < 2:
            return 0.0
        
        sharpes = [w["metrics"]["sharpe"] for w in windows]
        avg_pnls = [w["metrics"]["avg_pnl"] for w in windows]
        
        # æ–¹å‘ä¸€è‡´æ€§
        direction_consistency = sum(1 for p in avg_pnls if p > 0) / len(avg_pnls)
        
        # Sharpe è®Šç•°ä¿‚æ•¸ï¼ˆè¶Šä½è¶Šç©©å®šï¼‰
        sharpe_cv = np.std(sharpes) / (np.abs(np.mean(sharpes)) + 0.01)
        sharpe_stability = 1.0 / (1.0 + sharpe_cv)
        
        # ç¶œåˆåˆ†æ•¸
        stability = 0.5 * direction_consistency + 0.5 * sharpe_stability
        
        return float(stability)


# =============================================================================
# Monte Carlo Simulator
# =============================================================================

class MonteCarloSimulator:
    """
    è’™åœ°å¡ç¾…æ¨¡æ“¬å™¨
    
    æ¨¡æ“¬ç­–ç•¥åœ¨ä¸åŒå¸‚å ´æ¢ä»¶ä¸‹çš„è¡¨ç¾
    """
    
    def __init__(
        self,
        base_pnl_distribution: np.ndarray,
        n_simulations: int = 1000,
        n_periods: int = 252,  # äº¤æ˜“æ—¥
    ):
        """
        Args:
            base_pnl_distribution: åŸºç¤ PnL åˆ†ä½ˆ
            n_simulations: æ¨¡æ“¬æ¬¡æ•¸
            n_periods: æ¨¡æ“¬æœŸæ•¸
        """
        self.base_distribution = base_pnl_distribution
        self.n_simulations = n_simulations
        self.n_periods = n_periods
    
    def run(self) -> Dict[str, Any]:
        """
        åŸ·è¡Œè’™åœ°å¡ç¾…æ¨¡æ“¬
        
        Returns:
            æ¨¡æ“¬çµæœ
        """
        simulated_paths = []
        final_pnls = []
        max_drawdowns = []
        
        for _ in range(self.n_simulations):
            # å¾åˆ†ä½ˆä¸­æŠ½æ¨£
            daily_pnls = np.random.choice(self.base_distribution, size=self.n_periods, replace=True)
            
            # è¨ˆç®—ç´¯ç© PnL
            cumulative = np.cumsum(daily_pnls)
            
            # è¨ˆç®—æœ€å¤§å›æ’¤
            peak = np.maximum.accumulate(cumulative)
            drawdown = peak - cumulative
            max_dd = np.max(drawdown) / (np.max(peak) + 1e-8)
            
            simulated_paths.append(cumulative)
            final_pnls.append(cumulative[-1])
            max_drawdowns.append(max_dd)
        
        final_pnls = np.array(final_pnls)
        max_drawdowns = np.array(max_drawdowns)
        
        return {
            "final_pnl": {
                "mean": float(np.mean(final_pnls)),
                "std": float(np.std(final_pnls)),
                "median": float(np.median(final_pnls)),
                "percentile_5": float(np.percentile(final_pnls, 5)),
                "percentile_95": float(np.percentile(final_pnls, 95)),
                "prob_positive": float(np.mean(final_pnls > 0)),
            },
            "max_drawdown": {
                "mean": float(np.mean(max_drawdowns)),
                "percentile_95": float(np.percentile(max_drawdowns, 95)),
            },
            "paths": np.array(simulated_paths),
        }


# =============================================================================
# Robustness Tester
# =============================================================================

class RobustnessTester:
    """
    ç©©å¥æ€§æ¸¬è©¦å™¨
    
    æ¸¬è©¦ç­–ç•¥å°åƒæ•¸è®ŠåŒ–çš„æ•æ„Ÿåº¦
    """
    
    def __init__(
        self,
        model: BaseAlgorithm,
        base_env_factory: Callable,
    ):
        """
        Args:
            model: RL æ¨¡å‹
            base_env_factory: åŸºç¤ç’°å¢ƒå·¥å» 
        """
        self.model = model
        self.base_env_factory = base_env_factory
    
    def test_parameter_sensitivity(
        self,
        param_name: str,
        param_values: List[float],
        n_episodes: int = 10,
    ) -> Dict[str, List[float]]:
        """
        æ¸¬è©¦åƒæ•¸æ•æ„Ÿåº¦
        
        Args:
            param_name: åƒæ•¸åç¨±
            param_values: åƒæ•¸å€¼åˆ—è¡¨
            n_episodes: æ¯å€‹å€¼çš„æ¸¬è©¦ episode æ•¸
        
        Returns:
            å„åƒæ•¸å€¼çš„ç¸¾æ•ˆ
        """
        results = {
            "param_values": param_values,
            "avg_pnls": [],
            "std_pnls": [],
            "sharpes": [],
        }
        
        for value in param_values:
            # å»ºç«‹ç’°å¢ƒï¼ˆä¿®æ”¹åƒæ•¸ï¼‰
            env = self.base_env_factory()
            if hasattr(env, param_name):
                setattr(env, param_name, value)
            elif hasattr(env.unwrapped, param_name):
                setattr(env.unwrapped, param_name, value)
            
            # è©•ä¼°
            pnls = []
            for _ in range(n_episodes):
                obs, _ = env.reset()
                done = False
                episode_pnl = 0.0
                
                while not done:
                    action, _ = self.model.predict(obs, deterministic=True)
                    obs, reward, terminated, truncated, _ = env.step(action)
                    done = terminated or truncated
                    episode_pnl += reward
                
                pnls.append(episode_pnl)
            
            env.close()
            
            avg_pnl = np.mean(pnls)
            std_pnl = np.std(pnls)
            sharpe = avg_pnl / std_pnl if std_pnl > 0 else 0.0
            
            results["avg_pnls"].append(float(avg_pnl))
            results["std_pnls"].append(float(std_pnl))
            results["sharpes"].append(float(sharpe))
        
        return results
    
    def test_slippage_sensitivity(
        self,
        slippage_bps_range: List[float] = [0, 1, 2, 5, 10],
        n_episodes: int = 10,
    ) -> Dict[str, Any]:
        """æ¸¬è©¦æ»‘é»æ•æ„Ÿåº¦"""
        return self.test_parameter_sensitivity("slippage_bps", slippage_bps_range, n_episodes)
    
    def test_fee_sensitivity(
        self,
        fee_rate_range: List[float] = [0.0001, 0.0002, 0.0004, 0.0006, 0.001],
        n_episodes: int = 10,
    ) -> Dict[str, Any]:
        """æ¸¬è©¦æ‰‹çºŒè²»æ•æ„Ÿåº¦"""
        return self.test_parameter_sensitivity("fee_rate", fee_rate_range, n_episodes)


# =============================================================================
# Report Generator
# =============================================================================

class BacktestReportGenerator:
    """å›æ¸¬å ±å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, output_dir: str):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
    
    def generate_report(
        self,
        backtest_result: BacktestResult,
        wf_result: WalkForwardResult = None,
        mc_result: Dict = None,
        robustness_result: Dict = None,
    ) -> str:
        """
        ç”Ÿæˆå®Œæ•´å ±å‘Š
        
        Returns:
            å ±å‘Šæª”æ¡ˆè·¯å¾‘
        """
        report = {
            "backtest": backtest_result.to_dict(),
        }
        
        if wf_result:
            report["walk_forward"] = wf_result.to_dict()
        
        if mc_result:
            # ç§»é™¤å¤§å‹æ•¸çµ„
            mc_summary = {k: v for k, v in mc_result.items() if k != "paths"}
            report["monte_carlo"] = mc_summary
        
        if robustness_result:
            report["robustness"] = robustness_result
        
        # å„²å­˜ JSON
        report_path = self.output_dir / "backtest_report.json"
        with open(report_path, "w") as f:
            json.dump(report, f, indent=2)
        
        # ç”Ÿæˆæ–‡å­—å ±å‘Š
        text_report = self._generate_text_report(report)
        text_path = self.output_dir / "backtest_report.txt"
        with open(text_path, "w") as f:
            f.write(text_report)
        
        return str(report_path)
    
    def _generate_text_report(self, report: Dict) -> str:
        """ç”Ÿæˆæ–‡å­—å ±å‘Š"""
        lines = []
        lines.append("=" * 60)
        lines.append("BACKTEST REPORT")
        lines.append("=" * 60)
        
        bt = report.get("backtest", {})
        lines.append("\nğŸ“Š Performance Metrics:")
        lines.append(f"  Total PnL: ${bt.get('total_pnl', 0):,.2f}")
        lines.append(f"  Average PnL: ${bt.get('avg_pnl', 0):,.2f}")
        lines.append(f"  Sharpe Ratio: {bt.get('sharpe_ratio', 0):.4f}")
        lines.append(f"  Max Drawdown: {bt.get('max_drawdown', 0):.2%}")
        lines.append(f"  Calmar Ratio: {bt.get('calmar_ratio', 0):.4f}")
        
        lines.append("\nğŸ“ˆ Trading Statistics:")
        lines.append(f"  Total Trades: {bt.get('total_trades', 0)}")
        lines.append(f"  Win Rate: {bt.get('win_rate', 0):.2%}")
        lines.append(f"  Profit Factor: {bt.get('profit_factor', 0):.2f}")
        
        lines.append("\nâš ï¸ Risk Metrics:")
        lines.append(f"  VaR (95%): ${bt.get('var_95', 0):,.2f}")
        lines.append(f"  CVaR (95%): ${bt.get('cvar_95', 0):,.2f}")
        
        if "walk_forward" in report:
            wf = report["walk_forward"]
            agg = wf.get("aggregate_metrics", {})
            lines.append("\nğŸ”„ Walk-Forward Analysis:")
            lines.append(f"  Windows: {agg.get('n_windows', 0)}")
            lines.append(f"  Overall Sharpe: {agg.get('overall_sharpe', 0):.4f}")
            lines.append(f"  Positive Windows: {agg.get('positive_windows', 0):.2%}")
            lines.append(f"  Stability Score: {wf.get('stability_score', 0):.4f}")
        
        if "monte_carlo" in report:
            mc = report["monte_carlo"]
            fp = mc.get("final_pnl", {})
            lines.append("\nğŸ² Monte Carlo Simulation:")
            lines.append(f"  Mean Final PnL: ${fp.get('mean', 0):,.2f}")
            lines.append(f"  5th Percentile: ${fp.get('percentile_5', 0):,.2f}")
            lines.append(f"  95th Percentile: ${fp.get('percentile_95', 0):,.2f}")
            lines.append(f"  Prob. Positive: {fp.get('prob_positive', 0):.2%}")
        
        lines.append("\n" + "=" * 60)
        
        return "\n".join(lines)
